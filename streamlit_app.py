# -*- coding: utf-8 -*-
# ì‹¤í–‰: streamlit run streamlit_app.py --server.port 8501 --server.address 0.0.0.0
import io
import os
from base64 import b64encode
import numpy as np
import pandas as pd
import requests
import streamlit as st

from pyecharts.charts import Line
from pyecharts import options as opts
from pyecharts.globals import ThemeType
from streamlit_echarts import st_pyecharts

# -------------------------------------------------
# ê¸°ë³¸ ì„¤ì • + í°íŠ¸ ì£¼ì…
# -------------------------------------------------
st.set_page_config(page_title="í•´ìˆ˜ë©´ ìƒìŠ¹ ëŒ€ì‹œë³´ë“œ (ECharts)", layout="wide", page_icon="ğŸŒŠ")

def inject_font_css(font_path="/fonts/Pretendard-Bold.ttf", family="Pretendard"):
    if not os.path.exists(font_path):
        st.warning(f"í°íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {font_path}")
        return
    with open(font_path, "rb") as f:
        font_data = b64encode(f.read()).decode("utf-8")
    css = f"""
    <style>
    @font-face {{
        font-family: '{family}';
        src: url(data:font/ttf;base64,{font_data}) format('truetype');
        font-weight: 700; font-style: normal; font-display: swap;
    }}
    html, body, [class*="css"] {{
        font-family: '{family}', -apple-system, BlinkMacSystemFont, "Segoe UI",
                     Roboto, "Helvetica Neue", Arial, "Noto Sans KR", "Apple SD Gothic Neo",
                     "Nanum Gothic", "Malgun Gothic", sans-serif !important;
    }}
    </style>
    """
    st.markdown(css, unsafe_allow_html=True)

inject_font_css("/fonts/Pretendard-Bold.ttf", family="Pretendard")

# -------------------------------------------------
# í—¤ë”
# -------------------------------------------------
st.title("ğŸŒŠ ì „ì§€êµ¬ í‰ê·  í•´ìˆ˜ë©´(GMSL) â€” 1900s â†’ 2025")
st.caption("ì¡°ìœ„ê³„ ì¬êµ¬ì„±(CSIRO) + ìœ„ì„± ê³ ë„ê³„(NOAA/DataHub) ê²°í•© Â· Streamlit Ã— ECharts")

with st.expander("ğŸ“ ë°ì´í„° ì†ŒìŠ¤ ì•ˆë‚´"):
    st.markdown(
        """
- **ì¥ê¸° ì‹œê³„ì—´(1880~2009)**: CSIRO ì¡°ìœ„ê³„ ê¸°ë°˜ ì¬êµ¬ì„± (DataHub ê²½ìœ  CSV ì‚¬ìš©)
- **ìœ„ì„± ì‹œê¸°(1993~í˜„ì¬)**: DataHub ì›”ë³„ altimetry CSV â†’ ì‹¤íŒ¨ ì‹œ NOAA STAR ì›ë³¸ CSV íŒŒì„œë¡œ ëŒ€ì²´
- ë„¤íŠ¸ì›Œí¬/URL ë³€ê²½ ì‹œë¥¼ ëŒ€ë¹„í•´ ë°ëª¨ ë°ì´í„°ë¥¼ ìë™ ì‚¬ìš©í•©ë‹ˆë‹¤.
        """
    )

# -------------------------------------------------
# ì›ê²© CSV ë¡œë” & íŒŒì„œ
# -------------------------------------------------
def fetch_csv_from_candidates(candidates, **read_csv_kwargs) -> pd.DataFrame:
    """í›„ë³´ URLì„ ì°¨ë¡€ëŒ€ë¡œ ì‹œë„í•˜ì—¬ ì½ê¸°"""
    last_err = None
    for url in candidates:
        try:
            r = requests.get(url, timeout=25)
            r.raise_for_status()
            if "parse_dates" in read_csv_kwargs or "usecols" in read_csv_kwargs:
                df = pd.read_csv(io.BytesIO(r.content), **read_csv_kwargs)
            else:
                df = pd.read_csv(io.BytesIO(r.content))
            df["__source_url__"] = url
            return df
        except Exception as e:
            last_err = e
    if last_err:
        raise last_err
    raise RuntimeError("No URL candidates provided")

def read_noaa_altimetry_csv(url: str) -> pd.DataFrame:
    """NOAA STAR CSV(ì£¼ì„/ê°€ë³€ í¬ë§·) â†’ date, gmsl_mm ë¡œ í‘œì¤€í™”"""
    r = requests.get(url, timeout=25)
    r.raise_for_status()
    txt = r.text

    # 1) ì£¼ì„/ë¹ˆì¤„ ì œê±°
    lines = [ln for ln in txt.splitlines() if ln.strip() and not ln.strip().startswith("#")]
    if not lines:
        raise ValueError("NOAA CSV: ë°ì´í„° ì¤„ì´ ì—†ìŠµë‹ˆë‹¤.")
    raw = "\n".join(lines)

    # 2) êµ¬ë¶„ì ì¶”ì •(ì½¤ë§ˆ ìš°ì„ , ì•„ë‹ˆë©´ ê³µë°±)
    sep = "," if lines[0].count(",") > 0 else r"\s+"

    # 3) ê´€ëŒ€í•œ íŒŒì„œ
    df = pd.read_csv(io.StringIO(raw), sep=sep, engine="python", header=None)

    # === ë‚ ì§œì—´ ì¶”ì • ===
    c0 = df.iloc[:, 0]

    def decyear_to_datetime(y):
        y = float(y)
        year = int(np.floor(y))
        rem = y - year
        return pd.Timestamp(year, 1, 1) + pd.to_timedelta(rem * 365.25, unit="D")

    # ë¬¸ìì—´ ë‚ ì§œ / ì†Œìˆ˜ì—°ë„ / (year,month) ì¼€ì´ìŠ¤ë³„ ì²˜ë¦¬
    if c0.astype(str).str.contains(r"[-/]", regex=True).any():
        d = pd.to_datetime(c0, errors="coerce")
        val_candidates = list(range(1, df.shape[1]))
    elif pd.to_numeric(c0, errors="coerce").notna().all() and (c0.astype(float).between(1800, 2100)).all():
        d = c0.astype(float).map(decyear_to_datetime)
        val_candidates = list(range(1, df.shape[1]))
    elif df.shape[1] >= 2 and pd.to_numeric(df.iloc[:, 0], errors="coerce").notna().all() and \
         pd.to_numeric(df.iloc[:, 1], errors="coerce").notna().all():
        d = pd.to_datetime(dict(year=df.iloc[:, 0].astype(int), month=df.iloc[:, 1].astype(int), day=1), errors="coerce")
        val_candidates = list(range(2, df.shape[1]))
    else:
        d = pd.to_datetime(c0, errors="coerce")
        val_candidates = list(range(1, df.shape[1]))

    # === ê°’ ì—´ ì¶”ì • ===
    valcol = None
    for col in val_candidates:
        if pd.api.types.is_numeric_dtype(df.iloc[:, col]) or \
           pd.to_numeric(df.iloc[:, col], errors="coerce").notna().mean() > 0.9:
            valcol = col
            break
    if valcol is None:
        # ë’¤ì—ì„œë¶€í„° ìˆ«ì ë§ì€ ì—´ ì„ íƒ
        for col in reversed(range(1, df.shape[1])):
            if pd.to_numeric(df.iloc[:, col], errors="coerce").notna().mean() > 0.5:
                valcol = col
                break
    if valcol is None:
        raise ValueError("NOAA CSV ê°’ ì—´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    out = pd.DataFrame({"date": d, "gmsl_mm": pd.to_numeric(df.iloc[:, valcol], errors="coerce")})
    out = out.dropna().sort_values("date")
    out["__source_url__"] = url
    return out

# -------------------------------------------------
# ë°ì´í„° ì†ŒìŠ¤ URL
# -------------------------------------------------
CSIRO_CANDIDATES = [
    # DataHub: CSIRO ì¬êµ¬ì„±(1880â€“2009) ì›”ë³„
    "https://datahub.io/core/sea-level-rise/r/csiro_recons_gmsl_mo_2015.csv"
]
ALTIMETRY_CANDIDATES = [
    # DataHub: ìœ„ì„± ì›”ë³„ altimetry (Time, GMSL (monthly), GMSL (smoothed))
    "https://datahub.io/core/sea-level-rise/r/csiro_alt_seas_inc.csv",
    # NOAA STAR ì›ë³¸ (ì£¼ì„ í¬í•¨, ì „ìš© íŒŒì„œ ì‚¬ìš©)
    "https://www.star.nesdis.noaa.gov/socd/lsa/SeaLevelRise/slr/slr_sla_gbl_free_all_66.csv",
]

# -------------------------------------------------
# ë°ëª¨ ë°±ì—…
# -------------------------------------------------
def demo_fallback() -> tuple[pd.DataFrame, pd.DataFrame]:
    dates_a = pd.date_range("1900-01-01", "1992-12-01", freq="MS")
    mm_a = np.linspace(0, 120, len(dates_a)) + np.random.normal(0, 2, len(dates_a))
    df_a = pd.DataFrame({"date": dates_a, "gmsl_mm": mm_a, "__source_url__": "DEMO: CSIRO-like"})

    dates_b = pd.date_range("1993-01-01", "2025-12-01", freq="MS")
    mm_b = mm_a[-1] + np.linspace(0, 110, len(dates_b)) + np.random.normal(0, 2, len(dates_b))
    df_b = pd.DataFrame({"date": dates_b, "gmsl_mm": mm_b, "__source_url__": "DEMO: NOAA-like"})
    return df_a, df_b

# -------------------------------------------------
# ë¡œë“œ & ê²°í•©
# -------------------------------------------------
@st.cache_data(show_spinner=True, ttl=60*30)
def load_sources():
    c, n = None, None

    # CSIRO ì¬êµ¬ì„±(ì›”ë³„)
    try:
        c = fetch_csv_from_candidates(
            CSIRO_CANDIDATES,
            usecols=["Time", "GMSL"],      # DataHub ìŠ¤í‚¤ë§ˆ
            parse_dates=["Time"],
        )
        c = c.rename(columns={"Time": "date", "GMSL": "gmsl_mm"})
        c = c[["date", "gmsl_mm", "__source_url__"]].dropna().sort_values("date")
    except Exception as e:
        st.warning(f"CSIRO ì‹¤ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ â†’ ë°ëª¨ ëŒ€ì²´: {e}")
        c = None

    # ìœ„ì„±(altimetry)
    try:
        # 1) DataHub altimetry ìš°ì„ 
        try:
            n = fetch_csv_from_candidates(
                ALTIMETRY_CANDIDATES[:1],
                usecols=["Time", "GMSL (monthly)"],
                parse_dates=["Time"],
            )
            n = n.rename(columns={"Time": "date", "GMSL (monthly)": "gmsl_mm"})
            n = n[["date", "gmsl_mm", "__source_url__"]].dropna().sort_values("date")
        except Exception:
            # 2) ì‹¤íŒ¨ ì‹œ NOAA ì›ë³¸ íŒŒì„œ ì‚¬ìš©
            n = read_noaa_altimetry_csv(ALTIMETRY_CANDIDATES[1])
    except Exception as e:
        st.warning(f"ìœ„ì„± ì‹¤ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ â†’ ë°ëª¨ ëŒ€ì²´: {e}")
        n = None

    # Fallback
    if c is None or n is None:
        demo_c, demo_n = demo_fallback()
        c = demo_c if c is None else c
        n = demo_n if n is None else n

    return c, n

def unify_concat(df_a, df_b):
    """1993ë…„ ì´í›„ëŠ” ìœ„ì„±ê°’ ìš°ì„ ìœ¼ë¡œ ê²°í•©"""
    a = df_a.copy(); b = df_b.copy()
    a["date"] = pd.to_datetime(a["date"]); b["date"] = pd.to_datetime(b["date"])
    a["src"] = "ì¡°ìœ„ê³„ ì¬êµ¬ì„± (CSIRO)"
    b["src"] = "ìœ„ì„± ê³ ë„ê³„ (NOAA)"
    start_b = b["date"].min()
    a = a[a["date"] < start_b]
    return pd.concat([a, b], ignore_index=True).sort_values("date")

df_csi, df_noaa = load_sources()
full = unify_concat(df_csi, df_noaa)

# -------------------------------------------------
# ì‚¬ì´ë“œë°”(í•œêµ­ì–´)
# -------------------------------------------------
st.sidebar.header("âš™ï¸ ì„¤ì •")
theme = ThemeType.LIGHT  # ê³ ì •(ì›í•˜ë©´ ë¼ë””ì˜¤ë¡œ í† ê¸€ ê°€ëŠ¥)
unit = st.sidebar.radio("ë‹¨ìœ„", ["mm", "inch"], index=0, horizontal=True)
smooth = st.sidebar.checkbox("12ê°œì›” ì´ë™í‰ê· (ìŠ¤ë¬´ë”©)", value=True)
show_markers = st.sidebar.checkbox("í¬ì¸íŠ¸ í‘œì‹œ", value=False)

min_year = int(full["date"].dt.year.min())
max_year = int(full["date"].dt.year.max())
default_start = max(1900, min_year)
default_end = min(2025, max_year)

st.sidebar.markdown("---")
year_range = st.sidebar.slider("í‘œì‹œ ê¸°ê°„(ì—°ë„)", min_value=min_year,
                               max_value=max(2025, max_year),
                               value=(default_start, default_end), step=1)

# -------------------------------------------------
# ê°€ê³µ
# -------------------------------------------------
plot_df = full.copy()
plot_df["year"] = plot_df["date"].dt.year
plot_df = plot_df[(plot_df["year"] >= year_range[0]) & (plot_df["year"] <= year_range[1])]
plot_df = plot_df.sort_values("date")

if smooth:
    plot_df["gmsl_mm_smooth"] = plot_df.groupby("src")["gmsl_mm"].transform(lambda s: s.rolling(12, min_periods=1).mean())
    value_col = "gmsl_mm_smooth"
else:
    value_col = "gmsl_mm"

if unit == "inch":
    plot_df["value"] = plot_df[value_col] / 25.4
    unit_label = "in"
    unit_label_ko = "ì¸ì¹˜"
else:
    plot_df["value"] = plot_df[value_col]
    unit_label = "mm"
    unit_label_ko = "mm"

# -------------------------------------------------
# í†µê³„: ë³€í™”ëŸ‰/ì—°í‰ê·  ìƒìŠ¹ë¥ 
# -------------------------------------------------
def annual_rate(df):
    s = df.sort_values("date")[["date", "value"]].dropna()
    if len(s) < 2: return np.nan, np.nan
    change = s["value"].iloc[-1] - s["value"].iloc[0]
    years = (s["date"].iloc[-1] - s["date"].iloc[0]).days / 365.25
    if years <= 0: return np.nan, np.nan
    return change, change / years

change, rate = annual_rate(plot_df)

# -------------------------------------------------
# ì¶”ì„¸ì„ (ì„ í˜•íšŒê·€)
# -------------------------------------------------
def trend_series(df):
    g = df[["date", "value"]].dropna().sort_values("date")
    if len(g) < 2: return pd.DataFrame(columns=["date","trend"]), np.nan
    year_float = g["date"].dt.year + (g["date"].dt.dayofyear - 1) / 365.25
    p = np.polyfit(year_float.values, g["value"].values, 1)  # slope, intercept
    trend_vals = np.polyval(p, year_float.values)
    return pd.DataFrame({"date": g["date"].values, "trend": trend_vals}), p[0]

trend_df, slope_per_year = trend_series(plot_df)

# -------------------------------------------------
# ECharts ë¹Œë” (KOR ë¼ë²¨ + í°íŠ¸ + íˆ´ë°•ìŠ¤ + ê¸°ì¤€ì„ )
# -------------------------------------------------
def build_line_chart(df, trend_df, theme, unit_label, unit_label_ko, show_markers=False):
    # ì „ì²´ ì›” ë²”ìœ„ë¡œ xì¶• êµ¬ì„±, ê° ì‹œë¦¬ì¦ˆëŠ” ëˆ„ë½ì›” Noneìœ¼ë¡œ
    start = df["date"].min()
    end   = df["date"].max()
    x = pd.period_range(start, end, freq="M").strftime("%Y-%m").tolist()

    color_map = {
        "ì¡°ìœ„ê³„ ì¬êµ¬ì„± (CSIRO)": "#ff7f50",
        "ìœ„ì„± ê³ ë„ê³„ (NOAA)": "#3b82f6",
        "ì¶”ì„¸ì„ ": "#10b981",
    }

    chart = Line(init_opts=opts.InitOpts(theme=theme, width="1000px", height="540px"))
    chart.add_xaxis(xaxis_data=x)

    for name, g in df.groupby("src"):
        g = g.sort_values("date").copy()
        g["xkey"] = g["date"].dt.strftime("%Y-%m")
        m = dict(zip(g["xkey"], g["value"].round(2)))
        y_full = [m.get(xx, None) for xx in x]
        chart.add_yaxis(
            series_name=name,
            y_axis=y_full,
            is_smooth=True,
            symbol="circle",
            symbol_size=4,
            is_symbol_show=show_markers,
            is_connect_nones=False,
            linestyle_opts=opts.LineStyleOpts(width=3, opacity=0.95, color=color_map[name]),
            areastyle_opts=opts.AreaStyleOpts(opacity=0.18, color=color_map[name]),
        )

    if not trend_df.empty:
        trend_df = trend_df.sort_values("date").copy()
        trend_df["xkey"] = trend_df["date"].dt.strftime("%Y-%m")
        tmap = dict(zip(trend_df["xkey"], trend_df["trend"].round(2)))
        y_tr_full = [tmap.get(xx, None) for xx in x]
        chart.add_yaxis(
            series_name="ì¶”ì„¸ì„ ",
            y_axis=y_tr_full,
            is_smooth=False,
            symbol="none",
            is_connect_nones=False,
            linestyle_opts=opts.LineStyleOpts(width=2, type_="dashed", color=color_map["ì¶”ì„¸ì„ "]),
            areastyle_opts=opts.AreaStyleOpts(opacity=0),
        )

    chart.set_global_opts(
        legend_opts=opts.LegendOpts(
            pos_top="2%", pos_left="center",
            textstyle_opts=opts.TextStyleOpts(font_family="Pretendard")
        ),
        tooltip_opts=opts.TooltipOpts(
            trigger="axis", axis_pointer_type="cross",
            value_formatter=f"{{value}} {unit_label_ko}"
        ),
        datazoom_opts=[opts.DataZoomOpts(type_="slider", range_start=0, range_end=100),
                       opts.DataZoomOpts(type_="inside")],
        xaxis_opts=opts.AxisOpts(
            type_="category", boundary_gap=False,
            axislabel_opts=opts.LabelOpts(font_family="Pretendard"),
            name_textstyle_opts=opts.TextStyleOpts(font_family="Pretendard"),
        ),
        yaxis_opts=opts.AxisOpts(
            name=f"ëˆ„ì  í•´ìˆ˜ë©´ ë³€í™” ({unit_label_ko})",
            splitline_opts=opts.SplitLineOpts(is_show=True),
            axislabel_opts=opts.LabelOpts(font_family="Pretendard"),
            name_textstyle_opts=opts.TextStyleOpts(font_family="Pretendard"),
        ),
        toolbox_opts=opts.ToolboxOpts(
            is_show=True,
            feature=opts.ToolBoxFeatureOpts(
                save_as_image=opts.ToolBoxFeatureSaveAsImageOpts(title="PNG ì €ì¥"),
                restore=opts.ToolBoxFeatureRestoreOpts(),
                data_view=opts.ToolBoxFeatureDataViewOpts(is_show=False),
            )
        ),
    )
    chart.set_series_opts(
        markline_opts=opts.MarkLineOpts(
            data=[opts.MarkLineItem(y=0, name="ê¸°ì¤€ì„  (0)")],
            linestyle_opts=opts.LineStyleOpts(type_="dashed", opacity=0.5),
        )
    )
    return chart

chart = build_line_chart(plot_df[["date","src","value"]],
                         trend_df, theme, unit_label, unit_label_ko,
                         show_markers=show_markers)
st_pyecharts(chart, height="540px",
             key=f"echarts-{unit}-{year_range}-{smooth}-{show_markers}")

# -------------------------------------------------
# ë©”íŠ¸ë¦­ ì¹´ë“œ + í‘œ
# -------------------------------------------------
col1, col2, col3, col4 = st.columns(4)
with col1:
    st.metric("ê¸°ê°„", f"{year_range[0]}â€“{year_range[1]}")
with col2:
    st.metric(f"ë³€í™”ëŸ‰ ({unit_label_ko})", f"{(0 if np.isnan(change) else change):.1f}")
with col3:
    st.metric(f"ì—°í‰ê·  ìƒìŠ¹ë¥  ({unit_label_ko}/ë…„)", f"{(0 if np.isnan(rate) else rate):.2f}")
with col4:
    st.metric("ë°ì´í„° í¬ì¸íŠ¸", f"{len(plot_df):,}")

with st.expander("ğŸ§¾ ì›ìë£Œ ë¯¸ë¦¬ë³´ê¸°"):
    st.dataframe(
        plot_df[["date","src","value"]]
        .rename(columns={"date":"ë‚ ì§œ","src":"ìë£Œì›","value":f"í•´ìˆ˜ë©´({unit})"})
        .reset_index(drop=True),
        use_container_width=True
    )

st.markdown("---")
st.caption("â“’ ë¯¸ë¦¼ë§ˆì´ìŠ¤í„°ê³  1í•™ë…„ 4ë°˜ 4ì¡° **ë§ˆìŒë°”ë‹¤ê±´ê°•ì¡°** Â· ë²”ë¡€ í´ë¦­ìœ¼ë¡œ ì‹œë¦¬ì¦ˆ ìˆ¨ê¹€/ê°•ì¡°, í•˜ë‹¨ ìŠ¬ë¼ì´ë” ê¸°ê°„ íƒìƒ‰, ìš°ìƒë‹¨ íˆ´ë°” PNG ì €ì¥ ê°€ëŠ¥")
